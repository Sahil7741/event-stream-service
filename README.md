# ğŸš€ Event Streaming Service with Kafka  

## ğŸ“Œ Overview  

This project is a **high-performance event streaming system** built using **Kafka** and **Go**. It allows **producers** to send structured messages to a Kafka topic and **consumers** to efficiently process those messages in real-time. Designed for **low latency, high throughput, and scalability**, this system is ideal for handling event-driven architectures.  

## ğŸ— Tech Stack  

- **Go** - Backend programming language.  
- **Kafka** - Distributed event streaming platform.  
- **Docker** - Containerization for Kafka and Zookeeper.  
- **REST API** - For message publishing.  

## ğŸ”¥ Features  

âœ… **Processes 10,000+ messages per second**  
âœ… **Sub-100ms event processing latency**  
âœ… **Multi-worker consumers for parallel processing**  
âœ… **Fault tolerance with structured logging & error handling**  
âœ… **Scalable architecture with Kafka & Docker**  

## ğŸ“‚ Project Structure  

```
ğŸ“¦ event-stream-service  
 â”£ ğŸ“œ main.go          # REST API with Kafka producer  
 â”£ ğŸ“œ publisher.go     # Standalone Kafka message producer  
 â”£ ğŸ“œ consumer.go      # Multi-threaded Kafka consumer  
 â”£ ğŸ“œ docker-compose.yml # Kafka and Zookeeper setup  
 â”£ ğŸ“œ README.md        # Documentation  
```

## âš™ï¸ Setup & Usage  

### ğŸ›  Prerequisites  

- **Docker & Docker-Compose** installed  
- **Go (1.19+)** installed  

### 1ï¸âƒ£ Start Kafka & Zookeeper  

Run the following command to start Kafka and Zookeeper:  

```sh
docker-compose up -d
```

### 2ï¸âƒ£ Run the Producer API  

Start the producer API:  

```sh
go run main.go
```

Send events using `cURL`:

```sh
curl -X POST http://localhost:8080/publish \
     -H "Content-Type: application/json" \
     -d '{"message": "Hello, Kafka!"}'
```

### 3ï¸âƒ£ Run the Consumer  

Start the consumer to receive messages:  

```sh
go run consumer.go
```

### 4ï¸âƒ£ Run the Publisher (Bulk Messaging)  

Send **10,000 messages** for performance testing:  

```sh
go run publisher.go
```

## ğŸ“Š Performance Benchmark  

- **Achieved 10,000+ messages per second**  
- **Distributed workload across multiple consumer workers**  
- **Ensured sub-100ms message processing latency**  

## ğŸš€ Future Enhancements  

- ğŸ“ˆ **Monitoring** with Prometheus & Grafana  
- ğŸ—„ **Database Integration** (PostgreSQL, Redis)  
- ğŸ“¡ **Scalability Improvements** with multi-broker Kafka  